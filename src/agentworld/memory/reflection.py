"""Reflection (semantic memory) implementation."""

from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Optional
import uuid
import numpy as np


@dataclass
class ReflectionConfig:
    """Configuration for reflection generation.

    Attributes:
        threshold: Accumulated importance needed to trigger reflection generation
        questions_per_reflection: Number of questions to generate and answer
        memories_per_question: Number of memories to retrieve per question
        min_reflection_importance: Minimum importance score for reflections (always high)
        enabled: Whether reflection generation is enabled
    """
    threshold: float = 100.0
    questions_per_reflection: int = 3
    memories_per_question: int = 10
    min_reflection_importance: float = 8.0
    enabled: bool = True


@dataclass
class Reflection:
    """Semantic memory entry representing a synthesized insight.

    Reflections are higher-level insights generated by analyzing multiple
    observations. They represent "what the agent believes/knows" rather than
    "what happened."

    Attributes:
        id: Unique identifier
        content: The insight or generalization
        timestamp: When the reflection was generated
        importance: Always high (8-10) since reflections are valuable
        embedding: Vector embedding for semantic similarity
        embedding_model: Model used to generate embedding
        source_memories: IDs of observations that led to this reflection
        questions_addressed: Questions this reflection answers
    """
    content: str
    timestamp: datetime = field(default_factory=datetime.now)
    importance: float = 8.0
    embedding: Optional[np.ndarray] = None
    embedding_model: Optional[str] = None
    source_memories: List[str] = field(default_factory=list)
    questions_addressed: List[str] = field(default_factory=list)
    id: str = field(default_factory=lambda: str(uuid.uuid4()))

    def __post_init__(self):
        """Ensure reflection importance is always high."""
        if self.importance < 8.0:
            self.importance = 8.0
        if self.importance > 10.0:
            self.importance = 10.0

    def to_dict(self) -> dict:
        """Convert reflection to dictionary for persistence."""
        return {
            "id": self.id,
            "content": self.content,
            "timestamp": self.timestamp.isoformat(),
            "importance": self.importance,
            "embedding": self.embedding.tolist() if self.embedding is not None else None,
            "embedding_model": self.embedding_model,
            "source_memories": self.source_memories,
            "questions_addressed": self.questions_addressed,
        }

    @classmethod
    def from_dict(cls, data: dict) -> "Reflection":
        """Create reflection from dictionary."""
        embedding = None
        if data.get("embedding") is not None:
            embedding = np.array(data["embedding"])

        timestamp = data.get("timestamp")
        if isinstance(timestamp, str):
            timestamp = datetime.fromisoformat(timestamp)
        elif timestamp is None:
            timestamp = datetime.now()

        return cls(
            id=data.get("id", str(uuid.uuid4())),
            content=data["content"],
            timestamp=timestamp,
            importance=data.get("importance", 8.0),
            embedding=embedding,
            embedding_model=data.get("embedding_model"),
            source_memories=data.get("source_memories", []),
            questions_addressed=data.get("questions_addressed", []),
        )

    def has_compatible_embedding(self, model: str) -> bool:
        """Check if this reflection's embedding is compatible with the given model."""
        if self.embedding is None:
            return False
        return self.embedding_model == model
